{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d8f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries \n",
    "# Keras\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import libraries \n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob \n",
    "import wave\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import IPython.display as ipd \n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from tensorflow.python.keras import optimizers\n",
    "import pyaudio\n",
    "import h5py\n",
    "\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "RAVDESS = \"data/RAVDESS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d00055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    768\n",
      "positive    576\n",
      "neutral      96\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# RAVDESS data handling\n",
    "# 1.Get data of RAVESS\n",
    "\n",
    "RAVDESS_list = os.listdir(RAVDESS)\n",
    "RAVDESS_list.sort()\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "path = []\n",
    "\n",
    "for i in RAVDESS_list:\n",
    "    folder_name = os.listdir(RAVDESS + i)\n",
    "    for f in folder_name:\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        path.append(RAVDESS + i + '/' + f)\n",
    "        \n",
    "RAVDESS_data_frame = pd.DataFrame(emotion)\n",
    "RAVDESS_data_frame = RAVDESS_data_frame.replace({1:'neutral', 2:'positive', 3:'positive', 4:'negative', 5:'negative', 6:'negative', 7:'negative', 8:'positive'})\n",
    "RAVDESS_data_frame = pd.concat([pd.DataFrame(gender),RAVDESS_data_frame],axis=1)\n",
    "RAVDESS_data_frame.columns = ['emotion']\n",
    "RAVDESS_data_frame['labels'] = RAVDESS_data_frame.emotion\n",
    "RAVDESS_data_frame['source'] = 'RAVDESS'  \n",
    "RAVDESS_data_frame = pd.concat([RAVDESS_data_frame,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "RAVDESS_data_frame = RAVDESS_data_frame.drop(['emotion'], axis=1)\n",
    "print(RAVDESS_data_frame.labels.value_counts())\n",
    "RAVDESS_data_frame.head()\n",
    "RAVDESS_data_frame.to_csv(\"Data_path_3type.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a348b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    }
   ],
   "source": [
    "ref = pd.read_csv(\"Data_path_3type.csv\")\n",
    "\n",
    "data_frame = pd.DataFrame(columns=['feature'])\n",
    "\n",
    "# loop feature extraction over the entire dataset\n",
    "counter=0\n",
    "for index,path in enumerate(ref.path):\n",
    "    X, sample_rate = librosa.load(path\n",
    "                                  , res_type='kaiser_fast'\n",
    "                                  ,duration=2.5\n",
    "                                  ,sr=44100*2\n",
    "                                  ,offset=0.5\n",
    "                                 )\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    \n",
    "    # mean as the feature. Could do min and max etc as well. \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                        sr=sample_rate, \n",
    "                                        n_mfcc=13),\n",
    "                    axis=0)\n",
    "    data_frame.loc[counter] = [mfccs]\n",
    "    counter=counter+1   \n",
    "\n",
    "# Check a few records to make sure its processed successfully\n",
    "print(len(data_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bb25c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 434)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>source</th>\n",
       "      <th>path</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>data/RAVDESS/Actor_01/03-01-01-01-01-01-01.wav</td>\n",
       "      <td>-66.685966</td>\n",
       "      <td>-66.685966</td>\n",
       "      <td>-66.685966</td>\n",
       "      <td>-66.685966</td>\n",
       "      <td>-66.685966</td>\n",
       "      <td>-66.685966</td>\n",
       "      <td>-66.685966</td>\n",
       "      <td>...</td>\n",
       "      <td>-63.782047</td>\n",
       "      <td>-65.159958</td>\n",
       "      <td>-66.379623</td>\n",
       "      <td>-66.370964</td>\n",
       "      <td>-65.050102</td>\n",
       "      <td>-62.615089</td>\n",
       "      <td>-63.867981</td>\n",
       "      <td>-66.252884</td>\n",
       "      <td>-65.178276</td>\n",
       "      <td>-64.132698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>data/RAVDESS/Actor_01/03-01-01-01-01-02-01.wav</td>\n",
       "      <td>-64.795509</td>\n",
       "      <td>-61.218655</td>\n",
       "      <td>-63.572693</td>\n",
       "      <td>-66.222389</td>\n",
       "      <td>-66.224869</td>\n",
       "      <td>-63.284908</td>\n",
       "      <td>-60.982262</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.224869</td>\n",
       "      <td>-66.224869</td>\n",
       "      <td>-66.224869</td>\n",
       "      <td>-66.224869</td>\n",
       "      <td>-66.224869</td>\n",
       "      <td>-66.224869</td>\n",
       "      <td>-66.224869</td>\n",
       "      <td>-66.224869</td>\n",
       "      <td>-66.224869</td>\n",
       "      <td>-66.224869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>data/RAVDESS/Actor_01/03-01-01-01-02-01-01.wav</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.829056</td>\n",
       "      <td>-66.891724</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "      <td>-66.986763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>data/RAVDESS/Actor_01/03-01-01-01-02-02-01.wav</td>\n",
       "      <td>-66.507835</td>\n",
       "      <td>-66.507835</td>\n",
       "      <td>-66.507835</td>\n",
       "      <td>-66.507835</td>\n",
       "      <td>-66.507835</td>\n",
       "      <td>-66.507835</td>\n",
       "      <td>-66.507835</td>\n",
       "      <td>...</td>\n",
       "      <td>-63.659512</td>\n",
       "      <td>-61.913033</td>\n",
       "      <td>-64.136932</td>\n",
       "      <td>-65.742035</td>\n",
       "      <td>-66.507835</td>\n",
       "      <td>-64.259415</td>\n",
       "      <td>-61.868252</td>\n",
       "      <td>-61.696602</td>\n",
       "      <td>-61.834988</td>\n",
       "      <td>-60.222519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>data/RAVDESS/Actor_01/03-01-02-01-01-01-01.wav</td>\n",
       "      <td>-70.706390</td>\n",
       "      <td>-70.706390</td>\n",
       "      <td>-70.706390</td>\n",
       "      <td>-70.706390</td>\n",
       "      <td>-70.706390</td>\n",
       "      <td>-70.706390</td>\n",
       "      <td>-70.706390</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.867104</td>\n",
       "      <td>-60.163128</td>\n",
       "      <td>-62.258419</td>\n",
       "      <td>-65.114487</td>\n",
       "      <td>-63.698933</td>\n",
       "      <td>-62.085384</td>\n",
       "      <td>-60.464443</td>\n",
       "      <td>-59.918438</td>\n",
       "      <td>-60.530823</td>\n",
       "      <td>-60.381058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels   source                                            path  \\\n",
       "0   neutral  RAVDESS  data/RAVDESS/Actor_01/03-01-01-01-01-01-01.wav   \n",
       "1   neutral  RAVDESS  data/RAVDESS/Actor_01/03-01-01-01-01-02-01.wav   \n",
       "2   neutral  RAVDESS  data/RAVDESS/Actor_01/03-01-01-01-02-01-01.wav   \n",
       "3   neutral  RAVDESS  data/RAVDESS/Actor_01/03-01-01-01-02-02-01.wav   \n",
       "4  positive  RAVDESS  data/RAVDESS/Actor_01/03-01-02-01-01-01-01.wav   \n",
       "\n",
       "           0          1          2          3          4          5  \\\n",
       "0 -66.685966 -66.685966 -66.685966 -66.685966 -66.685966 -66.685966   \n",
       "1 -64.795509 -61.218655 -63.572693 -66.222389 -66.224869 -63.284908   \n",
       "2 -66.986763 -66.986763 -66.986763 -66.986763 -66.986763 -66.986763   \n",
       "3 -66.507835 -66.507835 -66.507835 -66.507835 -66.507835 -66.507835   \n",
       "4 -70.706390 -70.706390 -70.706390 -70.706390 -70.706390 -70.706390   \n",
       "\n",
       "           6  ...        421        422        423        424        425  \\\n",
       "0 -66.685966  ... -63.782047 -65.159958 -66.379623 -66.370964 -65.050102   \n",
       "1 -60.982262  ... -66.224869 -66.224869 -66.224869 -66.224869 -66.224869   \n",
       "2 -66.986763  ... -65.829056 -66.891724 -66.986763 -66.986763 -66.986763   \n",
       "3 -66.507835  ... -63.659512 -61.913033 -64.136932 -65.742035 -66.507835   \n",
       "4 -70.706390  ... -57.867104 -60.163128 -62.258419 -65.114487 -63.698933   \n",
       "\n",
       "         426        427        428        429        430  \n",
       "0 -62.615089 -63.867981 -66.252884 -65.178276 -64.132698  \n",
       "1 -66.224869 -66.224869 -66.224869 -66.224869 -66.224869  \n",
       "2 -66.986763 -66.986763 -66.986763 -66.986763 -66.986763  \n",
       "3 -64.259415 -61.868252 -61.696602 -61.834988 -60.222519  \n",
       "4 -62.085384 -60.464443 -59.918438 -60.530823 -60.381058  \n",
       "\n",
       "[5 rows x 434 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pd.concat([ref,pd.DataFrame(data_frame['feature'].values.tolist())],axis=1)\n",
    "data_frame = data_frame.fillna(0)\n",
    "print(data_frame.shape)\n",
    "data_frame[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5142b7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-44.382664</td>\n",
       "      <td>-47.018936</td>\n",
       "      <td>-54.718075</td>\n",
       "      <td>-50.243736</td>\n",
       "      <td>-51.747402</td>\n",
       "      <td>-55.910515</td>\n",
       "      <td>-58.261299</td>\n",
       "      <td>-56.977737</td>\n",
       "      <td>-53.866367</td>\n",
       "      <td>-56.098293</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.030037</td>\n",
       "      <td>-23.761675</td>\n",
       "      <td>-23.705111</td>\n",
       "      <td>-24.690458</td>\n",
       "      <td>-23.974962</td>\n",
       "      <td>-24.142874</td>\n",
       "      <td>-24.684908</td>\n",
       "      <td>-26.125843</td>\n",
       "      <td>-27.759472</td>\n",
       "      <td>-27.305826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>-69.633110</td>\n",
       "      <td>-69.830307</td>\n",
       "      <td>-57.556004</td>\n",
       "      <td>-53.482651</td>\n",
       "      <td>-53.808090</td>\n",
       "      <td>-53.371056</td>\n",
       "      <td>-54.884232</td>\n",
       "      <td>-54.602116</td>\n",
       "      <td>-53.492924</td>\n",
       "      <td>-54.011311</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.089188</td>\n",
       "      <td>-55.895615</td>\n",
       "      <td>-54.901390</td>\n",
       "      <td>-55.646564</td>\n",
       "      <td>-58.701538</td>\n",
       "      <td>-57.238113</td>\n",
       "      <td>-56.695328</td>\n",
       "      <td>-59.327534</td>\n",
       "      <td>-58.136230</td>\n",
       "      <td>-57.129715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>-51.624596</td>\n",
       "      <td>-52.237976</td>\n",
       "      <td>-52.421047</td>\n",
       "      <td>-46.545433</td>\n",
       "      <td>-48.257938</td>\n",
       "      <td>-49.996357</td>\n",
       "      <td>-49.724094</td>\n",
       "      <td>-53.130497</td>\n",
       "      <td>-51.704124</td>\n",
       "      <td>-52.405331</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.864788</td>\n",
       "      <td>-46.920864</td>\n",
       "      <td>-48.456944</td>\n",
       "      <td>-48.651222</td>\n",
       "      <td>-51.213448</td>\n",
       "      <td>-51.993599</td>\n",
       "      <td>-49.663742</td>\n",
       "      <td>-47.144775</td>\n",
       "      <td>-49.029716</td>\n",
       "      <td>-52.649437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-66.581444</td>\n",
       "      <td>-66.581444</td>\n",
       "      <td>-66.581444</td>\n",
       "      <td>-66.581444</td>\n",
       "      <td>-66.581444</td>\n",
       "      <td>-66.581444</td>\n",
       "      <td>-66.581444</td>\n",
       "      <td>-66.581444</td>\n",
       "      <td>-66.581444</td>\n",
       "      <td>-66.581444</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.184643</td>\n",
       "      <td>-32.871849</td>\n",
       "      <td>-31.989889</td>\n",
       "      <td>-32.139725</td>\n",
       "      <td>-32.033432</td>\n",
       "      <td>-33.708683</td>\n",
       "      <td>-34.899204</td>\n",
       "      <td>-37.167942</td>\n",
       "      <td>-36.603119</td>\n",
       "      <td>-37.974979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>-45.586433</td>\n",
       "      <td>-47.635994</td>\n",
       "      <td>-50.179520</td>\n",
       "      <td>-50.912094</td>\n",
       "      <td>-50.116760</td>\n",
       "      <td>-49.179470</td>\n",
       "      <td>-49.236221</td>\n",
       "      <td>-48.963261</td>\n",
       "      <td>-47.886662</td>\n",
       "      <td>-47.749001</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.900581</td>\n",
       "      <td>-45.468338</td>\n",
       "      <td>-49.760113</td>\n",
       "      <td>-49.913940</td>\n",
       "      <td>-50.477028</td>\n",
       "      <td>-50.067268</td>\n",
       "      <td>-51.429726</td>\n",
       "      <td>-52.603394</td>\n",
       "      <td>-53.560162</td>\n",
       "      <td>-55.155289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "168 -44.382664 -47.018936 -54.718075 -50.243736 -51.747402 -55.910515   \n",
       "605 -69.633110 -69.830307 -57.556004 -53.482651 -53.808090 -53.371056   \n",
       "548 -51.624596 -52.237976 -52.421047 -46.545433 -48.257938 -49.996357   \n",
       "65  -66.581444 -66.581444 -66.581444 -66.581444 -66.581444 -66.581444   \n",
       "628 -45.586433 -47.635994 -50.179520 -50.912094 -50.116760 -49.179470   \n",
       "\n",
       "           6          7          8          9    ...        421        422  \\\n",
       "168 -58.261299 -56.977737 -53.866367 -56.098293  ... -24.030037 -23.761675   \n",
       "605 -54.884232 -54.602116 -53.492924 -54.011311  ... -54.089188 -55.895615   \n",
       "548 -49.724094 -53.130497 -51.704124 -52.405331  ... -47.864788 -46.920864   \n",
       "65  -66.581444 -66.581444 -66.581444 -66.581444  ... -32.184643 -32.871849   \n",
       "628 -49.236221 -48.963261 -47.886662 -47.749001  ... -47.900581 -45.468338   \n",
       "\n",
       "           423        424        425        426        427        428  \\\n",
       "168 -23.705111 -24.690458 -23.974962 -24.142874 -24.684908 -26.125843   \n",
       "605 -54.901390 -55.646564 -58.701538 -57.238113 -56.695328 -59.327534   \n",
       "548 -48.456944 -48.651222 -51.213448 -51.993599 -49.663742 -47.144775   \n",
       "65  -31.989889 -32.139725 -32.033432 -33.708683 -34.899204 -37.167942   \n",
       "628 -49.760113 -49.913940 -50.477028 -50.067268 -51.429726 -52.603394   \n",
       "\n",
       "           429        430  \n",
       "168 -27.759472 -27.305826  \n",
       "605 -58.136230 -57.129715  \n",
       "548 -49.029716 -52.649437  \n",
       "65  -36.603119 -37.974979  \n",
       "628 -53.560162 -55.155289  \n",
       "\n",
       "[5 rows x 431 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(data_frame.drop(['path','labels','source'],axis=1)\n",
    "                                                    , data_frame.labels\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "# Check the dataset now \n",
    "X_train.head()\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55fbd7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.422069</td>\n",
       "      <td>1.095086</td>\n",
       "      <td>0.216448</td>\n",
       "      <td>0.739628</td>\n",
       "      <td>0.548048</td>\n",
       "      <td>0.057818</td>\n",
       "      <td>-0.224314</td>\n",
       "      <td>-0.074326</td>\n",
       "      <td>0.295085</td>\n",
       "      <td>0.031048</td>\n",
       "      <td>...</td>\n",
       "      <td>1.871969</td>\n",
       "      <td>1.916299</td>\n",
       "      <td>1.930007</td>\n",
       "      <td>1.866689</td>\n",
       "      <td>1.942290</td>\n",
       "      <td>1.938418</td>\n",
       "      <td>1.916531</td>\n",
       "      <td>1.819044</td>\n",
       "      <td>1.650641</td>\n",
       "      <td>1.434452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>-1.473871</td>\n",
       "      <td>-1.582902</td>\n",
       "      <td>-0.124789</td>\n",
       "      <td>0.354127</td>\n",
       "      <td>0.305237</td>\n",
       "      <td>0.357450</td>\n",
       "      <td>0.176941</td>\n",
       "      <td>0.207883</td>\n",
       "      <td>0.339306</td>\n",
       "      <td>0.277622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.566869</td>\n",
       "      <td>-0.702910</td>\n",
       "      <td>-0.611386</td>\n",
       "      <td>-0.655114</td>\n",
       "      <td>-0.892077</td>\n",
       "      <td>-0.755273</td>\n",
       "      <td>-0.702835</td>\n",
       "      <td>-0.915805</td>\n",
       "      <td>-0.798045</td>\n",
       "      <td>-0.700013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0.591501</td>\n",
       "      <td>0.482386</td>\n",
       "      <td>0.492646</td>\n",
       "      <td>1.179807</td>\n",
       "      <td>0.959211</td>\n",
       "      <td>0.755632</td>\n",
       "      <td>0.790056</td>\n",
       "      <td>0.382702</td>\n",
       "      <td>0.551127</td>\n",
       "      <td>0.467366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061854</td>\n",
       "      <td>0.028614</td>\n",
       "      <td>-0.086391</td>\n",
       "      <td>-0.085246</td>\n",
       "      <td>-0.280903</td>\n",
       "      <td>-0.328411</td>\n",
       "      <td>-0.127451</td>\n",
       "      <td>0.087698</td>\n",
       "      <td>-0.063964</td>\n",
       "      <td>-0.379364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-1.123880</td>\n",
       "      <td>-1.201495</td>\n",
       "      <td>-1.210022</td>\n",
       "      <td>-1.204914</td>\n",
       "      <td>-1.199846</td>\n",
       "      <td>-1.201250</td>\n",
       "      <td>-1.212892</td>\n",
       "      <td>-1.215185</td>\n",
       "      <td>-1.210573</td>\n",
       "      <td>-1.207521</td>\n",
       "      <td>...</td>\n",
       "      <td>1.210349</td>\n",
       "      <td>1.173737</td>\n",
       "      <td>1.255090</td>\n",
       "      <td>1.259843</td>\n",
       "      <td>1.284561</td>\n",
       "      <td>1.159836</td>\n",
       "      <td>1.080710</td>\n",
       "      <td>0.909498</td>\n",
       "      <td>0.937750</td>\n",
       "      <td>0.670872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>1.284010</td>\n",
       "      <td>1.022645</td>\n",
       "      <td>0.762171</td>\n",
       "      <td>0.660079</td>\n",
       "      <td>0.740187</td>\n",
       "      <td>0.852017</td>\n",
       "      <td>0.848024</td>\n",
       "      <td>0.877742</td>\n",
       "      <td>1.003173</td>\n",
       "      <td>1.017504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064758</td>\n",
       "      <td>0.147008</td>\n",
       "      <td>-0.192554</td>\n",
       "      <td>-0.188112</td>\n",
       "      <td>-0.220797</td>\n",
       "      <td>-0.171623</td>\n",
       "      <td>-0.271959</td>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.429166</td>\n",
       "      <td>-0.558705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "168  1.422069  1.095086  0.216448  0.739628  0.548048  0.057818 -0.224314   \n",
       "605 -1.473871 -1.582902 -0.124789  0.354127  0.305237  0.357450  0.176941   \n",
       "548  0.591501  0.482386  0.492646  1.179807  0.959211  0.755632  0.790056   \n",
       "65  -1.123880 -1.201495 -1.210022 -1.204914 -1.199846 -1.201250 -1.212892   \n",
       "628  1.284010  1.022645  0.762171  0.660079  0.740187  0.852017  0.848024   \n",
       "\n",
       "          7         8         9    ...       421       422       423  \\\n",
       "168 -0.074326  0.295085  0.031048  ...  1.871969  1.916299  1.930007   \n",
       "605  0.207883  0.339306  0.277622  ... -0.566869 -0.702910 -0.611386   \n",
       "548  0.382702  0.551127  0.467366  ... -0.061854  0.028614 -0.086391   \n",
       "65  -1.215185 -1.210573 -1.207521  ...  1.210349  1.173737  1.255090   \n",
       "628  0.877742  1.003173  1.017504  ... -0.064758  0.147008 -0.192554   \n",
       "\n",
       "          424       425       426       427       428       429       430  \n",
       "168  1.866689  1.942290  1.938418  1.916531  1.819044  1.650641  1.434452  \n",
       "605 -0.655114 -0.892077 -0.755273 -0.702835 -0.915805 -0.798045 -0.700013  \n",
       "548 -0.085246 -0.280903 -0.328411 -0.127451  0.087698 -0.063964 -0.379364  \n",
       "65   1.259843  1.284561  1.159836  1.080710  0.909498  0.937750  0.670872  \n",
       "628 -0.188112 -0.220797 -0.171623 -0.271959 -0.361932 -0.429166 -0.558705  \n",
       "\n",
       "[5 rows x 431 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lts do data normalization \n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "\n",
    "# Check the dataset now \n",
    "X_train.head()\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a94eb7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 431)\n",
      "['negative' 'neutral' 'positive']\n"
     ]
    }
   ],
   "source": [
    "# Lets few preparation steps to get it into the correct format for Keras \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# one hot encode the target \n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(lb.classes_)\n",
    "# print(y_train[0:10])\n",
    "# print(y_test[0:10])\n",
    "\n",
    "# Pickel the lb object for future use \n",
    "filename = 'labels'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "606922c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 431, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "892ad437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 431, 256)          2304      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 431, 256)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 431, 256)          524544    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 431, 256)          0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 431, 256)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 53, 256)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 53, 128)           262272    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 53, 128)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 53, 128)           131200    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 53, 128)           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 53, 128)           131200    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 53, 128)           0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 53, 128)           131200    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 53, 128)           0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 53, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 6, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 6, 64)             65600     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 6, 64)             0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 6, 64)             32832     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 6, 64)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 384)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 1155      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,282,307\n",
      "Trainable params: 1,282,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cdd5785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/78 [====>.........................] - ETA: 18s - loss: 1.0778 - accuracy: 0.5769"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ef4207bbbe12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(X_train, y_train, batch_size=14, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "model_name = 'Emotion_Model_3type.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Save model and weights at %s ' % model_path)\n",
    "\n",
    "# Save the model to disk\n",
    "model_json = model.to_json()\n",
    "with open('model_json.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading json and model architecture \n",
    "json_file = open('model_json.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# Keras optimiser\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
